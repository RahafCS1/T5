{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "45fbb33b",
      "metadata": {
        "id": "45fbb33b"
      },
      "source": [
        "# LangChain Tutorial Exercises"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "34a0df42",
      "metadata": {
        "id": "34a0df42"
      },
      "source": [
        "\n",
        "In this notebook, you will practice using LangChain to interact with large language models (LLMs),\n",
        "build chains, agents, and utilize memory. Fill in the code blocks with your implementations.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "169dd23c",
      "metadata": {
        "id": "169dd23c"
      },
      "source": [
        "## Exercise 1: Basic LLM Query"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bf03f4a7",
      "metadata": {
        "id": "bf03f4a7"
      },
      "source": [
        "In this exercise, you will set up a basic interaction with the GROQ LLaMA model using LangChain.\n",
        "\n",
        "1. Initialize the LLM (Use GROQ and chose LLM).\n",
        "2. Create a prompt that asks the LLM to generate a story about a topic.\n",
        "3. Run the LLM chain to retrieve the response.\n",
        "\n",
        "**Steps**:\n",
        "- Import required modules from `langchain`.\n",
        "- Initialize the LLM with your GROQ API key.\n",
        "- Create a prompt template that takes a topic as input.\n",
        "- Create an LLM Chain and run it to get a response.\n",
        "\n",
        "Fill in the code below:\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain langchain-community langchain-groq duckduckgo-search geopy requests"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MMCiTBr7zYXl",
        "outputId": "e25d7965-15b4-4ac6-9580-225de0ed0704"
      },
      "id": "MMCiTBr7zYXl",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain in /usr/local/lib/python3.10/dist-packages (0.3.0)\n",
            "Requirement already satisfied: langchain-community in /usr/local/lib/python3.10/dist-packages (0.3.0)\n",
            "Requirement already satisfied: langchain-groq in /usr/local/lib/python3.10/dist-packages (0.2.0)\n",
            "Requirement already satisfied: duckduckgo-search in /usr/local/lib/python3.10/dist-packages (6.2.11)\n",
            "Requirement already satisfied: geopy in /usr/local/lib/python3.10/dist-packages (2.4.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (2.32.3)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.2)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.34)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.10.5)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n",
            "Requirement already satisfied: langchain-core<0.4.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.3.0)\n",
            "Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.3.0)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.1.121)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.26.4)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.9.1)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (8.5.0)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (0.6.7)\n",
            "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (2.5.2)\n",
            "Requirement already satisfied: groq<1,>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from langchain-groq) (0.11.0)\n",
            "Requirement already satisfied: click>=8.1.7 in /usr/local/lib/python3.10/dist-packages (from duckduckgo-search) (8.1.7)\n",
            "Requirement already satisfied: primp>=0.6.1 in /usr/local/lib/python3.10/dist-packages (from duckduckgo-search) (0.6.2)\n",
            "Requirement already satisfied: geographiclib<3,>=1.52 in /usr/local/lib/python3.10/dist-packages (from geopy) (2.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests) (3.8)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests) (2024.8.30)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.11.1)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (3.22.0)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (0.9.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from groq<1,>=0.4.1->langchain-groq) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from groq<1,>=0.4.1->langchain-groq) (1.7.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from groq<1,>=0.4.1->langchain-groq) (0.27.2)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from groq<1,>=0.4.1->langchain-groq) (1.3.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from groq<1,>=0.4.1->langchain-groq) (4.12.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.0->langchain) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.0->langchain) (24.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.17->langchain) (3.10.7)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.3 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.23.3)\n",
            "Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.10/dist-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community) (1.0.1)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.1.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->groq<1,>=0.4.1->langchain-groq) (1.2.2)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->groq<1,>=0.4.1->langchain-groq) (1.0.5)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->groq<1,>=0.4.1->langchain-groq) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.0->langchain) (3.0.0)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community) (1.0.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "5686ae2f",
      "metadata": {
        "id": "5686ae2f"
      },
      "outputs": [],
      "source": [
        "groq_api_key = \"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\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_groq import ChatGroq\n",
        "\n",
        "llm = ChatGroq(\n",
        "    model=\"llama-3.1-8b-instant\",\n",
        "    temperature=0.8,\n",
        "    max_tokens=None,\n",
        "    timeout=None,\n",
        "    max_retries=2,\n",
        "    api_key=groq_api_key\n",
        ")"
      ],
      "metadata": {
        "id": "fdqKEFbuzxLA"
      },
      "id": "fdqKEFbuzxLA",
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.prompts import PromptTemplate\n",
        "\n",
        "# Define the prompt template\n",
        "prompt = PromptTemplate(\n",
        "    input_variables=[\"المرور\"],\n",
        "    template=\"Write a short story about {المرور في الرياض}.\"\n",
        ")"
      ],
      "metadata": {
        "id": "JVxAvxC9z3pn"
      },
      "id": "JVxAvxC9z3pn",
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain import LLMChain\n",
        "\n",
        "# Create an LLM chain\n",
        "chain = LLMChain(llm=llm, prompt=prompt)\n",
        "\n",
        "# Run the chain with a specific topic\n",
        "response = chain.run(\"المرور في الرياض\")\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FQ8c2j8T0ROY",
        "outputId": "5d26c564-ba56-422a-cae3-247aaa167f6f"
      },
      "id": "FQ8c2j8T0ROY",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-5-14429c4dc79d>:4: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 1.0. Use RunnableSequence, e.g., `prompt | llm` instead.\n",
            "  chain = LLMChain(llm=llm, prompt=prompt)\n",
            "<ipython-input-5-14429c4dc79d>:7: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use invoke instead.\n",
            "  response = chain.run(\"المرور في الرياض\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "كانت مدينة الرياض مدينة زاخرة بالسيارات، حيث يتدفق المرور في الشوارع والممرات. كان الأشخاص يضطرون للانتظار في مواقف السيارات طویلة الأجل، ويسرعون بالع709طاء في المواقف القريبة.\n",
            "\n",
            "كانت مواعيد الرحلات بنطاق متساوي بين 20-50 دقيقة، وقد يكون الأشخاص فقدان للأوقات، أو قد يكون هم أولئك الذين يتسعون بأسرع ممکن إلى موعد مهم حيث قد يكونوا في كمين انتظار طویل.\n",
            "\n",
            "في أحد الأيام، كان أحمد ينتظر في موقف سيارته المتجاور بجانب مشكلة في الهواء الطلق، فكأنه خطرت في ذهن الإبن إن كان قد تكون التكلفة الخاطرية للسيارة قد شددت على تقطيع الوقت. \n",
            "\n",
            "فقد أدرك أحمد إن أثناء هذه المدة طویلة، كان مبدعو الرياض يصممون المزيد من الطرق الجديدة، المزيد من منحنيات الطرق، والمزيد من المشاة والجسور.\n",
            "\n",
            "ثم أدرك أن المرور في الرياض لم يكن ليست حضاريا إلا إذا كان بإمكان الأشخاص انتظار رحلات متعددة قبل وصولهم إلى وجهتهم، أي أن هذا هو الطريق الوحيد المتبنى للتعامل مع ذلك الخطر المتهدد للمدن الكبرى بملحوظة.\n",
            "\n",
            "فيما بعد، بدأ أحمد في الاستمتاع بالمناظر المزخرفة التي يراكبها أثناء انتظاره، فلم يعد يشعر بالضغط، بل كان يتمتع بالراحة والاسترخاء بينما ينظر إلى جدار المواقف المزدحمة بالسيارات.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain import LLMChain\n",
        "\n",
        "# Create an LLM chain\n",
        "chain = LLMChain(llm=llm, prompt=prompt)\n",
        "\n",
        "# Run the chain with a specific topic\n",
        "response = chain.run(\"زحمة الطرق في الرياض\")\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PNkuBD1W1ftS",
        "outputId": "92253796-5964-4b19-a174-495368c56ec9"
      },
      "id": "PNkuBD1W1ftS",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "كان يومًا حارًا في مدينة الرياض، شمس رعدية تلمع في السماء، ويمكن أن يرى كل فرد من سكان المدينة من خلال المرآة الشائعة تلوثة الجو بسبب السيارات. كانت زحمة الطرق، كانت مما يجعل كل شيء يبدو كإرهاق.\n",
            "\n",
            "كانت سارة في طريقة إلى العمل، وكانت قوية، ولكنها شعرت أن لديها أمور كثيرة على أيديها. فقد كان يومًا ضاربيًا، وكانت في متابعة للعملاء، وملفات العمل الكثيرة، وتأمل في أن تكون اليوم أفضل من الأيام السابقة.\n",
            "\n",
            "بينما كانت تبالغ في التفكير في الأشياء القادمة، لم تمنعها السيارات التي كانت حولها من الانجراف بعنف إلى اليمين، وكانت سارة في خطر، فتحسنت عندما تمكن الحارس من إيقاف السيارة التي كانت تتهيج عندها.\n",
            "\n",
            "تظاهر سارة بالحضور، بلمس عائدتها، وهي بعيدة عن التفكير. وعندما استدارت، باتت تبين لها أن السيارة التي كان يديرها الرجل كان يفترض بالكاد أن يلتسن لها، عجلة القيادة كان يُحاط بها ملابس شرسة، وبالقوة. وأمامها، كانت السيارة التي كان يديرها رجل آخرون، وكان يصرف الانتباه إلى كل شئ عندها، إلى أنه عندما نظر إلى اليمين، كان يجد سارة في ساحة الخطوة، وبدأ بالضحك، وقال للشاب الذي كان يعتدي على سارة \" أخذه لانتباهك\".\n",
            "\n",
            "خلال لما تسبب ذلك بالقلق، كان من بينهم شاب يعتدي على سارة، وبدا أنه لا يهمه شيء. وأخيرا، قررت أن تكون قوية وتمكنت من الدفاع عن نفسها.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1ff1b3fa",
      "metadata": {
        "id": "1ff1b3fa"
      },
      "source": [
        "## Exercise 2: Building a Conversational Agent"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4a6a1f26",
      "metadata": {
        "id": "4a6a1f26"
      },
      "source": [
        "\n",
        "In this exercise, you will create a conversational agent that can interact with a user, make decisions,\n",
        "and use external tools like a search tool.\n",
        "\n",
        "1. Define a tool.\n",
        "2. Create an agent that can decide whether to use the tool or interact with the LLM.\n",
        "3. Run the agent with various inputs.\n",
        "\n",
        "**Steps**:\n",
        "- Define the search tool using a function.\n",
        "- Initialize an agent using the tool and the LLM.\n",
        "- Run the agent with sample inputs.\n",
        "\n",
        "Fill in the code below:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "a6e3e8e2",
      "metadata": {
        "id": "a6e3e8e2"
      },
      "outputs": [],
      "source": [
        "from langchain_community.tools import DuckDuckGoSearchRun\n",
        "\n",
        "search = DuckDuckGoSearchRun()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.agents import initialize_agent, AgentType\n",
        "\n",
        "\n",
        "tools = [search]\n",
        "\n",
        "agent = initialize_agent(\n",
        "    tools=tools,\n",
        "    llm=llm,\n",
        "    agent_type=AgentType.ZERO_SHOT_REACT_DESCRIPTION\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nfnrC7Wg2QSk",
        "outputId": "2a04cc5b-f3e1-481a-9de9-3bb83c64fb89"
      },
      "id": "nfnrC7Wg2QSk",
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-8-0cd90e8bd997>:6: LangChainDeprecationWarning: The function `initialize_agent` was deprecated in LangChain 0.1.0 and will be removed in 1.0. Use Use new agent constructor methods like create_react_agent, create_json_agent, create_structured_chat_agent, etc. instead.\n",
            "  agent = initialize_agent(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "search.invoke({\"query\": \"كم عدد فصول السنة؟\"})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        },
        "id": "9sNUqxYoztO3",
        "outputId": "d97599e3-3b24-43f7-9f9e-3bcfb23ddc3d"
      },
      "id": "9sNUqxYoztO3",
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'كم عدد مواسم السنه. عدد فصول السنة هو أربعة، الشتاء والربيع والصيف والخريف، وتنتج هذه الفصول المتعاقبة عن دوران كوكب الأرض حول الشمس والميل المحوري النسبي للأرض إلى مسار الشمس، ويكون لكل فصل من تلك الفصول خصائص محددة ... وينشر \"اليوم السابع\" تفاصيل مواعيد فصول السنة بالعام الميلادى الجديد 2024، كما يلى: - فصل الربيع يبدأ الأربعاء 20 مارس 2024 ويستمر 92 يوما و17 ساعة. - فصل الصيف يبدأ الخميس 20 يونيو 2024 ويستمر 93 يوما و15 ... تتغير الفصول الأربعة على مدار العام نتيجة للزاوية التي تميل بها الأرض ودورانها حول الشمس، وتحدث هذه الاختلافات في الفصول بناءً على كمية الضوء الشمسي الذي يصل إلى الأرض أثناء دورانها حول ... تنقسم السنة إلى أربعة فصول رئيسية: الربيع والصيف والخريف والشتاء. يتميز كل فصل بخصائص مناخية وبيئية محددة. الفصول تتتالى في ترتيب ثابت: الخريف، الشتاء، الربيع، الصيف. يرجع ترتيب الفصول إلى ... لطالما نظر الناس إلى السماء لتحديد فصول السنة، في العصور القديمة، كانت روما أول من حدد رسميًا هذه الفصول من خلال إدخال التقويم اليولياني. وفي ذلك الوقت كانت الفصول تبدأ في أيام مُختلفة عن ...'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.agents import initialize_agent, AgentType\n",
        "\n",
        "# List of tools the agent can use\n",
        "tools = [search]\n",
        "\n",
        "# Initialize the agent\n",
        "agent = initialize_agent(\n",
        "    tools=tools,\n",
        "    llm=llm,\n",
        "    agent_type=AgentType.ZERO_SHOT_REACT_DESCRIPTION\n",
        ")"
      ],
      "metadata": {
        "id": "Wcfzc6OR3riR"
      },
      "id": "Wcfzc6OR3riR",
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = agent.run(\"Find info about Causes of heavy traffic in Riyadh\")\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1fZfpfWp2kkS",
        "outputId": "6b46cc38-76a1-4ff5-b911-a148e5c36c47"
      },
      "id": "1fZfpfWp2kkS",
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Agent stopped due to iteration limit or time limit.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3cf94d2f",
      "metadata": {
        "id": "3cf94d2f"
      },
      "source": [
        "## Exercise 3: Using LLM as Memory"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "53ff48d9",
      "metadata": {
        "id": "53ff48d9"
      },
      "source": [
        "\n",
        "In this exercise, you will use an LLM to summarize and retain information from conversations.\n",
        "\n",
        "1. Set up LLM-based memory.\n",
        "2. Create a conversation with the LLM and memory.\n",
        "3. Ask follow-up questions using memory to retrieve past context.\n",
        "\n",
        "**Steps**:\n",
        "- Initialize summarization-based memory.\n",
        "- Run a few queries and retrieve responses.\n",
        "- Ask follow-up questions that reference previous interactions.\n",
        "\n",
        "Fill in the code below:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "796557b9",
      "metadata": {
        "id": "796557b9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "141c321f-506e-497d-e277-40739fe302cf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-12-e6e306a6b8d0>:11: LangChainDeprecationWarning: The class `ConversationChain` was deprecated in LangChain 0.2.7 and will be removed in 1.0. Use RunnableWithMessageHistory: https://python.langchain.com/v0.2/api_reference/core/runnables/langchain_core.runnables.history.RunnableWithMessageHistory.html instead.\n",
            "  chain_with_buffer_memory = ConversationChain(llm=llm, memory=summary_memory)\n"
          ]
        }
      ],
      "source": [
        "from langchain.memory import ConversationSummaryMemory\n",
        "from langchain import ConversationChain\n",
        "\n",
        "# Initialize summarization-based memory\n",
        "summary_memory = ConversationSummaryMemory(llm=llm)\n",
        "\n",
        "# Clear memory\n",
        "summary_memory.clear()\n",
        "\n",
        "# Create a chain with LLM and buffer memory\n",
        "chain_with_buffer_memory = ConversationChain(llm=llm, memory=summary_memory)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Start a conversation\n",
        "res1 = chain_with_buffer_memory.run(\"Answer with short answer, give me a wrong sentence about Summer\")\n",
        "res2 = chain_with_buffer_memory.run(\"Answer with short answer, give me a correcr sentence about Summer\")\n",
        "res3 = chain_with_buffer_memory.run(\"From the previous conversations. What was these sentences and what is the True between them ?\")\n",
        "\n",
        "print(f'First Response: {res1}\\nSecond Response: {res2}\\nThird Response: {res3}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c-iofH8g0RQJ",
        "outputId": "6a6feb7a-aa9d-455c-b813-605fffdd546c"
      },
      "id": "c-iofH8g0RQJ",
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First Response: Summer is a season of the year that starts on the first Tuesday of February.\n",
            "Second Response: Summer is a season that starts on the first Tuesday of February and lasts for 9 months, giving way to Autumn on the following spring equinox.\n",
            "Third Response: It seems there's been some confusion. The previous conversation about Summer's start and duration was incorrect. \n",
            "\n",
            "The first sentence mentioned that Summer is the season that starts on the first Tuesday of February. This is incorrect, as Summer actually starts on the summer solstice, which varies between June 20 and June 22 in the Northern Hemisphere.\n",
            "\n",
            "The second sentence mentioned that Summer lasts for 9 months, giving way to Autumn on the following spring equinox. This is incorrect as well, as Summer actually lasts for 3 months (June, July, and August) and Autumn (or Fall) starts on the autumnal equinox, which typically falls on September 22 or 23 in the Northern Hemisphere.\n",
            "\n",
            "The truth, between these two incorrect sentences, is that they both contain false information about Summer's start and duration.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "630fe2fb",
      "metadata": {
        "id": "630fe2fb"
      },
      "source": [
        "## Exercise 4: Combining Tools and Memory"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "17dba76c",
      "metadata": {
        "id": "17dba76c"
      },
      "source": [
        "\n",
        "In this final exercise, you will build an intelligent agent that can use both tools (like an API) and memory.\n",
        "\n",
        "1. Define an external tool (like a weather API).\n",
        "2. Set up an agent that uses both the tool and LLM memory.\n",
        "3. Interact with the agent, combining memory and external data.\n",
        "\n",
        "**Steps**:\n",
        "- Define a weather API tool (mock or real API).\n",
        "- Initialize the agent with memory and the tool.\n",
        "- Run the agent with inputs, and check how it uses both memory and tools.\n",
        "\n",
        "Fill in the code below:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "5e11ad68",
      "metadata": {
        "id": "5e11ad68"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "from geopy.geocoders import Nominatim\n",
        "\n",
        "def get_weather_by_city(city_name: str):\n",
        "\n",
        "    geolocator = Nominatim(user_agent=\"LLMexercise\")\n",
        "\n",
        "    # location data (latitude and longitude) for the city\n",
        "    location = geolocator.geocode(city_name)\n",
        "\n",
        "    if location:\n",
        "        latitude = location.latitude\n",
        "        longitude = location.longitude\n",
        "    else:\n",
        "        return f\"City '{city_name}' not found.\"\n",
        "\n",
        "\n",
        "    url = f\"https://api.open-meteo.com/v1/forecast?latitude={latitude}&longitude={longitude}&current_weather=true\"\n",
        "\n",
        "\n",
        "    response = requests.get(url)\n",
        "\n",
        "\n",
        "    if response.status_code == 200:\n",
        "\n",
        "        weather_data = response.json()\n",
        "\n",
        "        # information from the response\n",
        "        current_weather = weather_data.get('current_weather', {})\n",
        "        temperature = current_weather.get('temperature')\n",
        "        windspeed = current_weather.get('windspeed')\n",
        "        winddirection = current_weather.get('winddirection')\n",
        "        weather_time = current_weather.get('time')\n",
        "\n",
        "        # weather information\n",
        "        return (\n",
        "            f\"Current weather in {city_name}:\\n\"\n",
        "            f\"Temperature: {temperature}°C\\n\"\n",
        "            f\"Wind Speed: {windspeed} m/s\\n\"\n",
        "            f\"Wind Direction: {winddirection}°\\n\"\n",
        "            f\"Time of data: {weather_time}\"\n",
        "        )\n",
        "    else:\n",
        "        return \"Failed to retrieve weather data.\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.agents import Tool\n",
        "\n",
        "weather = Tool(\n",
        "    name=\"weather\",\n",
        "    func=get_weather_by_city,\n",
        "    description=\"Gets the weather of a city.\"\n",
        ")"
      ],
      "metadata": {
        "id": "oD_u-0BX1ZTl"
      },
      "id": "oD_u-0BX1ZTl",
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.agents import initialize_agent, AgentType\n",
        "\n",
        "# List of tools the agent can use\n",
        "tools = [weather]\n",
        "\n",
        "# Initialize the agent\n",
        "agent = initialize_agent(\n",
        "    tools=tools,\n",
        "    llm=llm,\n",
        "    agent_type=AgentType.ZERO_SHOT_REACT_DESCRIPTION\n",
        ")"
      ],
      "metadata": {
        "id": "GRcBw0yL1Z1M"
      },
      "id": "GRcBw0yL1Z1M",
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = agent.run(\"What is the weather in Makkah Saudi Arabia?\")\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TIV-Llqn1dDb",
        "outputId": "20c60ba3-4503-464b-d286-0ee8abc9af69"
      },
      "id": "TIV-Llqn1dDb",
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The weather in Makkah Saudi Arabia is:\n",
            "\n",
            "- Temperature: 33.0°C\n",
            "- Wind Speed: 8.4 m/s\n",
            "- Wind Direction: 223°\n",
            "- Time of data: 2024-09-17T07:15\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "q_yDNlu23ia-"
      },
      "id": "q_yDNlu23ia-",
      "execution_count": 17,
      "outputs": []
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}